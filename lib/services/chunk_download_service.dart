import 'dart:async';
import 'dart:io';
import 'dart:math';
import 'package:crypto/crypto.dart';
import 'package:http/http.dart' as http;
import 'package:path/path.dart' as path;
import '../utils/logger.dart';

/// åˆ†ç‰‡ä¸‹è½½é…ç½®
class ChunkDownloadConfig {
  /// å¹¶è¡Œä¸‹è½½çº¿ç¨‹æ•°ï¼ˆé»˜è®¤8ï¼‰
  final int concurrency;
  
  /// æ¯ä¸ªåˆ†ç‰‡å¤§å°ï¼ˆé»˜è®¤2MBï¼‰
  final int chunkSize;
  
  /// å•ä¸ªåˆ†ç‰‡æœ€å¤§é‡è¯•æ¬¡æ•°
  final int maxRetries;
  
  /// è¿æ¥è¶…æ—¶æ—¶é—´
  final Duration connectTimeout;
  
  /// è¯»å–è¶…æ—¶æ—¶é—´
  final Duration readTimeout;

  const ChunkDownloadConfig({
    this.concurrency = 8,
    this.chunkSize = 2 * 1024 * 1024, // 2MB
    this.maxRetries = 3,
    this.connectTimeout = const Duration(seconds: 30),
    this.readTimeout = const Duration(seconds: 60),
  });
}

/// åˆ†ç‰‡ä¿¡æ¯
class ChunkInfo {
  final int index;
  final int start;
  final int end;
  int downloaded;
  bool completed;
  int retryCount;

  ChunkInfo({
    required this.index,
    required this.start,
    required this.end,
    this.downloaded = 0,
    this.completed = false,
    this.retryCount = 0,
  });

  int get size => end - start + 1;
}

/// ä¸‹è½½è¿›åº¦ä¿¡æ¯
class DownloadProgress {
  final int totalBytes;
  final int downloadedBytes;
  final int activeChunks;
  final double speed; // bytes per second
  final Duration? estimatedTime;

  DownloadProgress({
    required this.totalBytes,
    required this.downloadedBytes,
    required this.activeChunks,
    required this.speed,
    this.estimatedTime,
  });

  double get progress => totalBytes > 0 ? downloadedBytes / totalBytes : 0;
  String get progressPercent => '${(progress * 100).toStringAsFixed(1)}%';
  
  String get speedText {
    if (speed < 1024) return '${speed.toStringAsFixed(0)} B/s';
    if (speed < 1024 * 1024) return '${(speed / 1024).toStringAsFixed(1)} KB/s';
    return '${(speed / 1024 / 1024).toStringAsFixed(1)} MB/s';
  }
}


/// åˆ†ç‰‡ä¸‹è½½æœåŠ¡
/// æ”¯æŒå¤šçº¿ç¨‹å¹¶è¡Œä¸‹è½½ï¼Œæ–­ç‚¹ç»­ä¼ ï¼Œè‡ªåŠ¨é‡è¯•
class ChunkDownloadService {
  static final ChunkDownloadService _instance = ChunkDownloadService._internal();
  factory ChunkDownloadService() => _instance;
  ChunkDownloadService._internal();

  final ChunkDownloadConfig _config = const ChunkDownloadConfig();
  
  bool _isCancelled = false;
  final List<ChunkInfo> _chunks = [];
  int _totalBytes = 0;
  int _downloadedBytes = 0;
  DateTime? _startTime;
  int _lastBytes = 0;
  DateTime? _lastSpeedCheck;

  /// æ£€æŸ¥æœåŠ¡å™¨æ˜¯å¦æ”¯æŒ Range è¯·æ±‚
  Future<bool> supportsRangeRequest(String url) async {
    try {
      final response = await http.head(Uri.parse(url)).timeout(
        const Duration(seconds: 10),
      );
      
      final acceptRanges = response.headers['accept-ranges'];
      final contentLength = response.headers['content-length'];
      
      logger.debug('ğŸ” [åˆ†ç‰‡ä¸‹è½½] Accept-Ranges: $acceptRanges');
      logger.debug('ğŸ” [åˆ†ç‰‡ä¸‹è½½] Content-Length: $contentLength');
      
      return acceptRanges == 'bytes' && contentLength != null;
    } catch (e) {
      logger.warning('âš ï¸ [åˆ†ç‰‡ä¸‹è½½] æ£€æŸ¥Rangeæ”¯æŒå¤±è´¥: $e');
      return false;
    }
  }

  /// è·å–æ–‡ä»¶å¤§å°
  Future<int?> getFileSize(String url) async {
    try {
      final response = await http.head(Uri.parse(url)).timeout(
        const Duration(seconds: 10),
      );
      
      final contentLength = response.headers['content-length'];
      if (contentLength != null) {
        return int.tryParse(contentLength);
      }
      return null;
    } catch (e) {
      logger.error('âŒ [åˆ†ç‰‡ä¸‹è½½] è·å–æ–‡ä»¶å¤§å°å¤±è´¥: $e');
      return null;
    }
  }

  /// åˆ†ç‰‡å¹¶è¡Œä¸‹è½½
  /// [url] ä¸‹è½½åœ°å€
  /// [savePath] ä¿å­˜è·¯å¾„
  /// [onProgress] è¿›åº¦å›è°ƒ
  /// [expectedMd5] æœŸæœ›çš„MD5å€¼ï¼ˆå¯é€‰ï¼Œç”¨äºæ ¡éªŒï¼‰
  Future<String?> download({
    required String url,
    required String savePath,
    Function(DownloadProgress)? onProgress,
    String? expectedMd5,
    ChunkDownloadConfig? config,
  }) async {
    final cfg = config ?? _config;
    _isCancelled = false;
    _chunks.clear();
    _downloadedBytes = 0;
    _startTime = DateTime.now();
    _lastSpeedCheck = _startTime;
    _lastBytes = 0;

    try {
      logger.info('ğŸ“¥ [åˆ†ç‰‡ä¸‹è½½] å¼€å§‹ä¸‹è½½: $url');
      logger.info('ğŸ“ [åˆ†ç‰‡ä¸‹è½½] ä¿å­˜è·¯å¾„: $savePath');
      
      // 1. æ£€æŸ¥æ˜¯å¦æ”¯æŒåˆ†ç‰‡ä¸‹è½½
      final supportsRange = await supportsRangeRequest(url);
      if (!supportsRange) {
        logger.warning('âš ï¸ [åˆ†ç‰‡ä¸‹è½½] æœåŠ¡å™¨ä¸æ”¯æŒRangeè¯·æ±‚ï¼Œå›é€€åˆ°æ™®é€šä¸‹è½½');
        return await _fallbackDownload(url, savePath, onProgress);
      }

      // 2. è·å–æ–‡ä»¶å¤§å°
      final fileSize = await getFileSize(url);
      if (fileSize == null || fileSize <= 0) {
        logger.warning('âš ï¸ [åˆ†ç‰‡ä¸‹è½½] æ— æ³•è·å–æ–‡ä»¶å¤§å°ï¼Œå›é€€åˆ°æ™®é€šä¸‹è½½');
        return await _fallbackDownload(url, savePath, onProgress);
      }
      
      _totalBytes = fileSize;
      logger.info('ğŸ“Š [åˆ†ç‰‡ä¸‹è½½] æ–‡ä»¶å¤§å°: ${(_totalBytes / 1024 / 1024).toStringAsFixed(2)} MB');

      // 3. åˆ›å»ºåˆ†ç‰‡
      _createChunks(cfg.chunkSize);
      logger.info('ğŸ”¢ [åˆ†ç‰‡ä¸‹è½½] åˆ†ç‰‡æ•°é‡: ${_chunks.length}, å¹¶å‘æ•°: ${cfg.concurrency}');

      // 4. åˆ›å»ºä¸´æ—¶ç›®å½•å’Œåˆ†ç‰‡æ–‡ä»¶
      final tempDir = Directory('${savePath}_chunks');
      if (!await tempDir.exists()) {
        await tempDir.create(recursive: true);
      }

      // 5. å¹¶è¡Œä¸‹è½½æ‰€æœ‰åˆ†ç‰‡
      final completer = Completer<bool>();
      int activeDownloads = 0;
      int nextChunkIndex = 0;
      final errors = <String>[];

      void startNextChunk() async {
        if (_isCancelled || completer.isCompleted) return;
        
        while (activeDownloads < cfg.concurrency && nextChunkIndex < _chunks.length) {
          final chunk = _chunks[nextChunkIndex];
          nextChunkIndex++;
          activeDownloads++;
          
          _downloadChunk(
            url: url,
            chunk: chunk,
            tempDir: tempDir.path,
            config: cfg,
            onProgress: (bytes) {
              _downloadedBytes += bytes;
              _notifyProgress(onProgress, activeDownloads);
            },
          ).then((success) {
            activeDownloads--;
            if (!success && !_isCancelled) {
              errors.add('åˆ†ç‰‡ ${chunk.index} ä¸‹è½½å¤±è´¥');
            }
            
            if (_isCancelled) {
              if (!completer.isCompleted) completer.complete(false);
              return;
            }
            
            // æ£€æŸ¥æ˜¯å¦æ‰€æœ‰åˆ†ç‰‡éƒ½å®Œæˆ
            if (_chunks.every((c) => c.completed)) {
              if (!completer.isCompleted) completer.complete(true);
            } else if (activeDownloads == 0 && nextChunkIndex >= _chunks.length) {
              // æ‰€æœ‰ä»»åŠ¡éƒ½ç»“æŸä½†æœ‰åˆ†ç‰‡æœªå®Œæˆ
              if (!completer.isCompleted) completer.complete(false);
            } else {
              startNextChunk();
            }
          });
        }
      }

      // å¯åŠ¨åˆå§‹ä¸‹è½½ä»»åŠ¡
      startNextChunk();

      // ç­‰å¾…æ‰€æœ‰åˆ†ç‰‡å®Œæˆ
      final success = await completer.future;
      
      if (!success) {
        logger.error('âŒ [åˆ†ç‰‡ä¸‹è½½] ä¸‹è½½å¤±è´¥: ${errors.join(", ")}');
        await _cleanup(tempDir);
        return null;
      }

      // 6. åˆå¹¶åˆ†ç‰‡
      logger.info('ğŸ”— [åˆ†ç‰‡ä¸‹è½½] å¼€å§‹åˆå¹¶åˆ†ç‰‡...');
      final mergeSuccess = await _mergeChunks(tempDir.path, savePath);
      if (!mergeSuccess) {
        logger.error('âŒ [åˆ†ç‰‡ä¸‹è½½] åˆå¹¶åˆ†ç‰‡å¤±è´¥');
        await _cleanup(tempDir);
        return null;
      }

      // 7. æ¸…ç†ä¸´æ—¶æ–‡ä»¶
      await _cleanup(tempDir);

      // 8. æ ¡éªŒMD5ï¼ˆå¦‚æœæä¾›ï¼‰
      if (expectedMd5 != null && expectedMd5.isNotEmpty) {
        logger.info('ğŸ” [åˆ†ç‰‡ä¸‹è½½] æ ¡éªŒæ–‡ä»¶MD5...');
        final file = File(savePath);
        final bytes = await file.readAsBytes();
        final digest = md5.convert(bytes);
        final fileMd5 = digest.toString();
        
        if (fileMd5.toLowerCase() != expectedMd5.toLowerCase()) {
          logger.error('âŒ [åˆ†ç‰‡ä¸‹è½½] MD5æ ¡éªŒå¤±è´¥');
          logger.error('   æœŸæœ›: $expectedMd5');
          logger.error('   å®é™…: $fileMd5');
          await file.delete();
          return null;
        }
        logger.info('âœ… [åˆ†ç‰‡ä¸‹è½½] MD5æ ¡éªŒé€šè¿‡');
      }

      final duration = DateTime.now().difference(_startTime!);
      final avgSpeed = _totalBytes / duration.inSeconds;
      logger.info('âœ… [åˆ†ç‰‡ä¸‹è½½] ä¸‹è½½å®Œæˆï¼');
      logger.info('   è€—æ—¶: ${duration.inSeconds}ç§’');
      logger.info('   å¹³å‡é€Ÿåº¦: ${(avgSpeed / 1024 / 1024).toStringAsFixed(2)} MB/s');

      return savePath;
    } catch (e) {
      logger.error('âŒ [åˆ†ç‰‡ä¸‹è½½] ä¸‹è½½å¼‚å¸¸: $e');
      return null;
    }
  }

  /// å–æ¶ˆä¸‹è½½
  void cancel() {
    _isCancelled = true;
    logger.info('ğŸ›‘ [åˆ†ç‰‡ä¸‹è½½] ä¸‹è½½å·²å–æ¶ˆ');
  }

  /// åˆ›å»ºåˆ†ç‰‡
  void _createChunks(int chunkSize) {
    _chunks.clear();
    int start = 0;
    int index = 0;
    
    while (start < _totalBytes) {
      final end = min(start + chunkSize - 1, _totalBytes - 1);
      _chunks.add(ChunkInfo(
        index: index,
        start: start,
        end: end,
      ));
      start = end + 1;
      index++;
    }
  }

  /// ä¸‹è½½å•ä¸ªåˆ†ç‰‡
  Future<bool> _downloadChunk({
    required String url,
    required ChunkInfo chunk,
    required String tempDir,
    required ChunkDownloadConfig config,
    required Function(int) onProgress,
  }) async {
    final chunkFile = File(path.join(tempDir, 'chunk_${chunk.index}'));
    
    for (int retry = 0; retry <= config.maxRetries; retry++) {
      if (_isCancelled) return false;
      
      try {
        final request = http.Request('GET', Uri.parse(url));
        request.headers['Range'] = 'bytes=${chunk.start}-${chunk.end}';
        
        final response = await request.send().timeout(config.connectTimeout);
        
        if (response.statusCode != 206 && response.statusCode != 200) {
          throw Exception('HTTP ${response.statusCode}');
        }

        final sink = chunkFile.openWrite();
        int chunkDownloaded = 0;
        
        await for (var data in response.stream) {
          if (_isCancelled) {
            await sink.close();
            return false;
          }
          sink.add(data);
          chunkDownloaded += data.length;
          onProgress(data.length);
        }
        
        await sink.close();
        chunk.completed = true;
        chunk.downloaded = chunkDownloaded;
        
        return true;
      } catch (e) {
        chunk.retryCount++;
        logger.warning('âš ï¸ [åˆ†ç‰‡ä¸‹è½½] åˆ†ç‰‡ ${chunk.index} ç¬¬ ${retry + 1} æ¬¡å°è¯•å¤±è´¥: $e');
        
        if (retry < config.maxRetries) {
          await Future.delayed(Duration(seconds: pow(2, retry).toInt()));
        }
      }
    }
    
    return false;
  }

  /// åˆå¹¶åˆ†ç‰‡
  Future<bool> _mergeChunks(String tempDir, String savePath) async {
    try {
      final outputFile = File(savePath);
      final sink = outputFile.openWrite();
      
      for (int i = 0; i < _chunks.length; i++) {
        final chunkFile = File(path.join(tempDir, 'chunk_$i'));
        if (!await chunkFile.exists()) {
          logger.error('âŒ [åˆ†ç‰‡ä¸‹è½½] åˆ†ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: chunk_$i');
          await sink.close();
          return false;
        }
        
        final bytes = await chunkFile.readAsBytes();
        sink.add(bytes);
      }
      
      await sink.close();
      logger.info('âœ… [åˆ†ç‰‡ä¸‹è½½] åˆ†ç‰‡åˆå¹¶å®Œæˆ');
      return true;
    } catch (e) {
      logger.error('âŒ [åˆ†ç‰‡ä¸‹è½½] åˆå¹¶åˆ†ç‰‡å¼‚å¸¸: $e');
      return false;
    }
  }

  /// æ¸…ç†ä¸´æ—¶æ–‡ä»¶
  Future<void> _cleanup(Directory tempDir) async {
    try {
      if (await tempDir.exists()) {
        await tempDir.delete(recursive: true);
        logger.debug('ğŸ§¹ [åˆ†ç‰‡ä¸‹è½½] ä¸´æ—¶æ–‡ä»¶å·²æ¸…ç†');
      }
    } catch (e) {
      logger.warning('âš ï¸ [åˆ†ç‰‡ä¸‹è½½] æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: $e');
    }
  }

  /// é€šçŸ¥è¿›åº¦
  void _notifyProgress(Function(DownloadProgress)? onProgress, int activeChunks) {
    if (onProgress == null) return;
    
    final now = DateTime.now();
    double speed = 0;
    
    if (_lastSpeedCheck != null) {
      final elapsed = now.difference(_lastSpeedCheck!).inMilliseconds;
      if (elapsed > 500) { // æ¯500msè®¡ç®—ä¸€æ¬¡é€Ÿåº¦
        speed = (_downloadedBytes - _lastBytes) / (elapsed / 1000);
        _lastBytes = _downloadedBytes;
        _lastSpeedCheck = now;
      }
    }
    
    Duration? estimatedTime;
    if (speed > 0) {
      final remaining = _totalBytes - _downloadedBytes;
      estimatedTime = Duration(seconds: (remaining / speed).round());
    }
    
    onProgress(DownloadProgress(
      totalBytes: _totalBytes,
      downloadedBytes: _downloadedBytes,
      activeChunks: activeChunks,
      speed: speed,
      estimatedTime: estimatedTime,
    ));
  }

  /// å›é€€åˆ°æ™®é€šä¸‹è½½ï¼ˆå½“æœåŠ¡å™¨ä¸æ”¯æŒRangeæ—¶ï¼‰
  Future<String?> _fallbackDownload(
    String url,
    String savePath,
    Function(DownloadProgress)? onProgress,
  ) async {
    try {
      logger.info('ğŸ“¥ [æ™®é€šä¸‹è½½] å¼€å§‹ä¸‹è½½...');
      
      final request = http.Request('GET', Uri.parse(url));
      final response = await request.send();
      
      if (response.statusCode != 200) {
        throw Exception('HTTP ${response.statusCode}');
      }
      
      _totalBytes = response.contentLength ?? 0;
      _downloadedBytes = 0;
      
      final file = File(savePath);
      final sink = file.openWrite();
      
      await for (var chunk in response.stream) {
        if (_isCancelled) {
          await sink.close();
          await file.delete();
          return null;
        }
        sink.add(chunk);
        _downloadedBytes += chunk.length;
        _notifyProgress(onProgress, 1);
      }
      
      await sink.close();
      logger.info('âœ… [æ™®é€šä¸‹è½½] ä¸‹è½½å®Œæˆ');
      return savePath;
    } catch (e) {
      logger.error('âŒ [æ™®é€šä¸‹è½½] ä¸‹è½½å¤±è´¥: $e');
      return null;
    }
  }
}
